# transformer encoder NLP-portfolio
자연어, 생성형 , 강화학습 ai 포트폴리오

1) transformer encoder로 동의어 관계 분석
   
   epoch : 99, train_loss : 0.43970897793769836 , test_dataset : {'accuracy': 0.664927536231884, 'f1': 0.7987465181058496}(별도의 scheduling이나 checkpoint지정은 하지 않고 train dataset에 epoch100으로만 훈련함)
   
   pretrained transformer encoder model 쓰지 않음
   
추가 실험 예정

2) llm start
   i)
   ii) meta llama 사용해봄 7B짜리. 외부 데이터 1개(말 그대로 한개)를 모델의 입력에 맞는 format으로 구성해 fine tuning 해봄. 작동하는지 테스트해본 정도. 시각화나 테스트데이터에 대한 추론은 안 해봄

. soft actor critic mujoco half cheeath
   https://github.com/genji970/soft-actor-critic
   
. rl paper study
https://github.com/genji970/RL-stock-prediction-paper-study

. 수학 : 해석학 , 선대 , 테일러급수 등
